---
title: "2020-10-11-BERT-두_문장_관계_분류"
date: 2021-10-11T15:34:30-04:00
categories:
  - boostcamp
  - nlp
tags:
  - BERT
---


# BERT-두_문장_관계_분류

## task
주어진 두개의 문장에 대해 자연어 추론/ 의미론적 유사성

`cls + sen1 + sep + sen2 + sep` 이렇게 input으로 들어감. 이 두 문장의 관계를 학습.

## 데이터셋
### NLI(자연어 추론 Natural Language Inference): 맥락을 이해할 수 있는지? 
premise과 hypothesis이 주어진다. 
hypothesis가 참인 경우 / hypothesis가 거짓인 경우 / 명백하게 알 수 없는 경우 중 하나로 분류.

### Symantic text pair
두 문장의 의미가 같은지 판단. 레이블이 0과 1 중 하나 분류

## IRQA(Information Retrieval Question and Answering)
QA는 QA인데... 분류 QA이다. 일반적인 QA는 passage에서 정답 있는 위치 index 찾기인데 그거랑 다르다. 이미 정해진 질문에 정해진 답변이 있음. 챗봇에서 쿼리가 들어오면 유사도 계산해서 가장 비슷한 정해진 질문으로 치환 -> 거기에 맞는 답변을 반환. 그런데 유사도 계산한 이후에 symantic text pair 통해서 딥러닝으로 실제 유사한게 symantic하게 맞는지 확인도 한다.

너 이름이 뭐야? -> top 1이 우정이 뭐야? 라고 벡터화 되어 있는 경우가 꽤 있따. 그래서 symantic text pair으로 검증한 뒤에 정확한 응답 결과를 내보내는 것.

챗봇에서 많이 사용 함. 

실습 코드의 직관

유사한 문장 데이터가 주어짐.
당장 만들어야 하는 모델은 symantic text pair 모델이다. 
두 문장이 주어질 때 유사한지 아닌지를 판별해야 한다. 
주어진 데이터가 유사한 문장만을 가지고 있어서 유사하지 않은 데이터도 모아야 함.
랜덤하게 두 문장을 섞는다. 
문제점: 완전히 다른 문장들로만 묶여서 유사하지 않은 문장 찾는게 쉽다.
더 어렵게 하기: 의미적으로 다른 문장들이지만 유사한 벡터들을 찾아서 묶는다. 모델 입장에서 비슷한 벡터인데 다르게 구분해야 해서 어려운 task으로 전환!