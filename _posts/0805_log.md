---
title: "Post: 0805_log"
last_modified_at: 2021-08-02T16:20:02-05:00
categories:
  - Blog
  - Camp
tags:
  - python
  - camp
---
# py 5-1
## Exception
```
try:
    ...
except ZeroDivisionError:
    ...
except IndexError as i:
    ...
    print(i)
    print("Index Error Occurs!")
else:
    ...
    p
```

## built-in exception
IndexError
NameError
ZeroDivisionError
ValueError
FileNotFoundError

## try-except-else-finally

굳이 else가 있는 이유: else는 에러가 없을 때 실행. finally는 언제나 실행.
try clause에서 성공하면 연결해서 실행할 코드가 있을 때 else을 사용 함. 이런 특수한 상황에서 쓰기 때문에 흔히 보기는 쉽지 않다. 

```
try:
    ...
except:
    ...
else:
    ...
fianlly:
    ...
```

reference: https://stackoverflow.com/questions/16138232/is-it-a-good-practice-to-use-try-except-else-in-python

## raise Exception
```
...
raise ValueError("Value not typed")
```

## assert
```
decimal_number = ...
...
assert isinstance(decimal_number, int)
```

## file
```
f = open("dir_and_file.extension", "r")
contents = f.read()
...
f.close()
```

```
with open("dir_and_file.extension", "r")) as f:
    contents = f.read()
```

```
with open("dir_and_file.extension", "r")) as f:
    one_line = f.readlines()
    ...
```

```
with open("dir_and_file.extension", "w", encoding = "utf8)) as f:
    data = ...
    f.write(data)
```

## os
```
import os
os.mkdir("log)
```

## dir

```
if not os.path.isdir("log") # 현재 sys.path에 log가 없으면
    is.mkdir("log)
```

```
import pathlib

cwd = pathlib.Path.cwd()
cwd.parent
list(cwd.parents)
list(cwd.glob("*"))

#use with list
```

## pickle
f = open("file.pickle", "wb")
dta = ...
pickle.dump(data, f)
f.close()

f= open("file.pickle", "rb")
data = pickle.load(f)
f.close()

class 저장하기 등...

## logging
import logging

logging.debug(str_arg)
logging.info(str_arg)
logging.warning(str_arg)
logging.error(str_arg)
logging.critical(str_arg)

debug: 개발처리 기록
info: 처리 진행 되는 동안 알림(서버 로그 등)
warning: 의도치 않은 정보 입력이 들어옴. exception으로 예측한 값이 들어옴. 어쨌든 처리는 했음.
error: 프로그램은 돌아감. 처리 에러가 남. client가 요청한 파일 없음 등
critical: 프로그램 꺼졌음...

## logging level

logger = logging.getLogger("main")
stream_header = logging.StreamHandler()
logger.addHAndler(stream_handler)
logger.setLevel(logging.DEBUG)
logger.setLevel(logging.CRITICAL)

## config parser
```
# config.cfg

[Sect 1]
key1: val
key2: val
[Sect 2]
key3: val
[Sect 3]
key5: val

# .py
import configparser
config = configparser.ConfigParser()
config.sections()

config.read('config.cfg')
config.sections()

... = config['Sect1']['key1']
```

## argparser
import argparse
def argFunc():
    parser = argparse.ArgumentParser(description="show description to users")

    parser.add_argument('--key', type = int, default = ..., metavar = 'K', help = 'description of this option')
    ...

    args = parser.parse_args()
argFunc()

## logging formats

logging.Formatter('%(asctime)s %(levelname)s %(process)d %(message)s')


# py 5-2 data handling
import csv
reader = csv.reader(f, delimiter=',', quotechar='"', quoting = csv.QUOTE_ALL)

## 정규식
* saerch
* findall

파이썬 활용: https://www.w3schools.com/python/python_regex.asp

## beautiful soup
```
from bs4 import BeautifulSoup
soup = BeautifulSoup(books_xml, 'lxml)
soup.find_all(str_arg)
soup.find(str_arg).get_text()
...
```

## json
```
import json
with open('file.json', 'r', encoding = 'utf8') as f:
    data = f.read()
    dict = json.loads(data)

dict_data = { key : val, ...}
with open('file.json', 'w' ) as f:
    json.dump(dict_data, ff)

import requests
r = requests.get(url = ...)
status = r.json()

#use status as dictoinary...
```

# numpy


## comparison
```
a = np.array...
b = np.array...

a > b
a == b
# return boolean np array
# return each true and false
```
## all and any
np boolean array에서 True의 개수에 따라...

```
a = np.arange(...)
np.any(a > num)
# return boolean
np.all(a > num)
# return boolean
```

## comparison : logical_

```
a = boolean array...
b = boolean array...

np.logical_and(a, b)
# for each index, true if both brue

np.logical_and(a)
# reversed boolean array

np.logical_or(a, b)
# for each index, true at least one is True.

tmp1 = a > b #booelan array
tmp2 = a < b #booelan array

# the two are same below.
np.logical_and(tmp1, tmp2)
np.logical_and(a> b, a < b)
```


## np.where(condition, [true, false])

```
a = np.array...
np.where(a > 0, 3, 2)

# for each index, if true map 3, false map 2

np.where(a, 3)
# return array with True index

np.isnan(a)
# return boolean array

np.isfinite(a)
# return booelan array
# infinite number False
```

## fancy index

```
a = np.array...

# booelan index
i = np.array([True, False, ...],bool)
a[i] # return only True index

# int index
i = np.array([1, 4, 6, ...], int)
a[i] # return corresponding index as list
```


# 통계학 맛보기
* **데이터가 특정 확률분포를 따른다고 선험적으로(a priori) 가정**한 후 그 분포 를 결정하는 모수(parameter)를 추정하는 방법을 모수적(parametric) 방 법론이라 합니다

* 특정 확률분포를 가정하지 않고 데이터에 따라 모델의 구조 및 모수의 개수 가 유연하게 바뀌면 비모수(nonparametric) 방법론이라 부릅니다

* 기계적으로 확률분포를 가정해서는 안 되며, 데이터를 생성하는 원리를 먼
저 고려하는 것이 원칙입니다

* 각 분포마다 검정하는 방법들이 있으므로 모수를 추정한 후에는 반드시 검정을 해야 한다

* MLE why log?
  * 경사하강법으로 가능도를 최적화할 때 미분 연산을 사용하게 되는데, 로그
가능도를 사용하면 연산량을 O(n^2) 에서 O(n) 으로 줄여줍니다

* categorical distribution MLE

When there are d categories,
$$
    \begin{aligned}
        \mathcal{{l(\theta)}} 
        & = \sum_i^n \sum_k^d \log \theta_k^{I\{x_i = k\}}\\
        & = \sum_k^d n_k \log \theta_k^{I\{x_i = k\}}\\
        & = \sum_k^{d-1} n_k \log  + n_d \log \theta_{d}\\
        & = \sum_k^{d-1} n_k \log  + n_d \log ( 1 - \sum_k^{d-1} \theta_k )\\
        \frac{ \mathcal{{l(\theta)}}}{\theta_k}
        & = \frac{n_k}{p_k} + \frac{-n_d}{1-\sum_k^{d-1} \theta_k} = 0\\
        \hat p_k 
        & = \frac{n_k}{n_d}(1-\sum_k^{d-1} \theta_k)\\
        & = \frac{n_k}{n_d}p_d\\
        \sum p_k & = 1.\\

        \sum \hat p_k & = 1\\
        \implies \sum_k \frac{n_k}{n_d}p_d & = 1\\
        p_d & = \frac{n_d}{\sum n_k}\\
        p_k & = \frac{n_k}{n_d}p_d\\
        & = \frac{n_d}{\sum n_k} \frac{n_k}{n_d}\\
        & = \frac{n_d}{\sum n_k}
    \end{aligned}
$$

이렇게 풀지 않고... 일반적인 **표현**은 라그랑지 풀이법을 쓰는 것. 
$$
\max_\theta \mathcal{l}(\theta)\\
s.t. \sum \theta = 1
$$

라그랑지 상수를 적용하면 모양 자체는 비슷하게 나온다. 결국 d개의 parameter중에서 1개가 나머지 parameter들로 선형 종속되는 형태로 나옴. 라그랑지 승수를 정리하는 모양에서 조금 달라지긴 하지만 아이디어는 같다. 사실 라그랑지를 쓰는게 정석적인 방법 같은데, 생각 못하던 표현이었음. 

reference
http://www.iro.umontreal.ca/~slacoste/teaching/ift6269/A17/notes/lecture4.pdf
https://math.stackexchange.com/questions/421105/maximum-likelihood-estimator-of-parameters-of-multinomial-distribution

* multinomial districution의 combination factor은 상수라서 어차피 MLE 구할 때 노상관 됨 + convex 함수!

## 베이즈 정리
* liklihood: 현재 파라미터에서 데이터의 분포를 예측
* priori: 데이터를 보기 전 사전에 예측/가정/가설로 세워보는 분포

* 베이즈 정리와 metric의 의미와 연결시킬 수 있음. 

* 정보의 갱신

* 인과관계 추론

인과관계 기반 예측: 정확도가 엄청 높지는 않지만 데이터 분포가 변화해도 어느정도의 정확도를 유지할 수 있음.

조건부 기반 예측은 데이터 분포 바뀌면 그냥 망한다. 

인과관계 기반 예측 모델: 중첩요인(confusion factor)을 제거해야 함. 키가 크면 머리가 좋다. 

중첩요인을 제거하면 패러독스를 제거할 수 있음.