---
title: "MRC-INTRO-AND-PYTHON-BASICS"
last_modified_at: 2021-10-12T16:20:02-05:00
categories:
  - boostcamp
---

# MRC-INTRO-AND-PYTHON-BASICS

# Intro to MRC
* QA: 기계 독해. 지문이 주어지고 주어진 질의에 답변을 추론. Question+Context -> Answer.
* 우리 과제는 ODQA: 지문이 안주어짐. retrieve해서 지문을 선택하고, 그 다음에 주어진 지문들에서 QA 수행.
* 대부분의 검색 엔진. 구글. 네이버. 시리.
## MRC의 종류
1. Extractive Answer Dataset: 질의에 대한 답이 항상 지문에 있음. SQuad, korQuad, NewsQA, Natural Questions
2. 답이 지문에 없는 경우. Descriptive Narrative Answer Datasets. 답을 만들어 내야 함. 답 자체가 지문에 없음. 생성해 내야 함. MAS MACRO, Narrative QA
3. Multiple-choice Dataset: 질의에 대한 답을 객관식으로 주면 선택해야  함. 요즘은 MRC에서 잘 안씀. task가 동일하지 않아서. MCTest, RACE, ARC
## Challenges in MRC
1. 패러프레이징된 문장이 가장 어렵다. 단어들은 다른데, 내용은 같다. 질문의 단어들과 유사한 단어들이 아닌 답안이면 어려운 문제가 된다. 
2. Coreference: 그것, 이것 이런 답안도 어려움. 뭔지 몰라서.
3. 지문 내에 실제로 답안이 없을 때. 답이 있는 것처럼 보인다. 답이 없다고 출력해야 정답. SQuAD 2.0
## Multi-hop reasoning
* 흩어져 있는 정보를 찾아서 혼합해야 함. 여러 document을 전부 활용을 해야 함. 
* MRC 평가 모델
* EM: 레이블 답안과 모델이 낸 예측이 정확히 일치하는 샘플의 비율
* F1: 정확히 일치하지는 않을 때... 맞춘 글자의 비율
* 그런데 이 방법은 descriptive answer에서는 힘들다. EM에 해당하는 실제 답안이 거의 없어서. 그래서 ROUGE-L/BLEU을 쓴다. ROUGE-L은 Longest Common Subsequence 기반에서 가장 많이 겹치는 글자들을 기반으로 맞은 * 비율 파악. Recall. 
* BLEU: 예측과 레이블 사이의 precision. (uniform n-gram weight)

# unicode and tokenization
* unicode: 전세계 모든 문자를 일관된 정수 체계에 매핑. 
* utf-8: 문자를 이진수로 변환. 가장 많이 쓰는 인코딩 방식. 문자 타입에 따라서 다른 길이 바이트를 할당. 
* 1바이트: ASKII
* 2바이트: Arabic, Hebrew, European
* 3바이트: Basic Multilingual Plane. 한글 포함한 대부분은 현대 글자
* 4바이트: 모든 unicode. 이모지 포함. 

## 파이썬에서 unicode 다루기
* 3에서는 string 유니코드가 표준이다.
* ord: 문자를 uincode 숫자로 변환.
* chr: unicode 숫자를 글자로 변환.

* 한글은 조합형과 완성형이 있음.
* ㄱ + ㅏ을 따로
* 가가 1개의 문자

* 토크나이징
* 띄어쓰기 기준, 형태소, subword 기준
  
* Dataset
* KorQuAD. LG CNS에서 개발. huggingface 데이터셋을 활용!
  
* KorQuad의 질문 유형:
* 구문 변형(패러패르에징)
* 어휘 변형(유의어)
* 어휘 변형(일반상식): 해외에서 활동 중인... -> 영국에서 활동 중인... 
* 여러 문장 근거 종합(multiple sentence 혼합)

# 2
# Extraction based MRC
지문에 답변이 항상 있다.  text의 위치만 파악하면 되는 문제. 

f1

$$
\text { Precision }=
$$

$$
\begin{gathered}
\text { Precision }=\frac{ { num(same-token) }}{ { num(pred-tokens) }} \\
\text { Recall }=\frac{ { num(same-token })}{ { num(groud-tokens) }} \\
F 1=\frac{2 \times \text { Precision } \times \text { Recall }}{ { Precision }+\text { Recall }}
\end{gathered}
$$
same token: prediction과 ground truth의 동일하게 나타난 단어 토큰

# preprocess
subword, BPE

# 모델
input: Context, Question, Answer -> 몇번째 부터 몇번째 토큰인지 예측.

모델 출력 값: 토큰의 위치. 토큰 단위로 몇번째 토큰인지 찾는다. 잘린 subword에 대해서는 최소한으로 포함하는 단어를 선택?  


# fine tuning
BERT QA

# post processing
이후 내용은 baseline 코드의 내용을 설명.