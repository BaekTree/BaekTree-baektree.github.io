---
title: "0813_GAN"
last_modified_at: 2021-08-06T16:20:02-05:00
categories:
  - boostcamp
tags:
  - camp
---

# week 2 Fri 0813
## Generative Model
* stanford deep generative model io으로부터 강의록을 만드셨다고 한다.
* 문장을 만드는, 이미지를 만드는, 생성하는 것이 gen의 전부가 아니다. 
  * 알고 있는 gen model: 강아지 이미지가 주어지면, 모델이 학습해서 강아지를 샘플링하는 모댈ㅇ르 만들 수 있다. 
  * 뿐만 아니라 density estimation도 할 수 있다. 사진을 집어넣으면 확률 값 1개가 나와서 이미지가 강아지 같은지 고양이 같은지 확률값으로 구분할 수 있다. 마치 분류 문제와 같다. 따라서 generative 모델은 분류 문제를 포함하고 있다. 사진의 분포를 파악해서 구분 가능! 

* 입력에 대한 확률 값을 얻어낼 수 있는 모델을 explicit gen모델이라고 부른다. 
* 단순히 generation만 하는 모델을 implicit gen model.
* unsupervised representation model도 gen에 포함된다. feature model이라고도 부른다. 피쳐(hidden representation)를 알아서 찾아냄. 레이블 없이. 

* 일단 주어진 사진에 대한 probability을 알면 구분도 가능하고 sampling도 가능하다. 그러면 입력 x에 대해서, p(x)을 어떻게 구하나? 

* p(x) 학습하기
  * 직관: 이전 시간의 혹은 주변의 데이터를 보고 당장 맞춰야 하는 값을 예측하자. 살펴봐야 하는 이전/주변의 값의 범위의 수는 일종의 하이퍼 파라미터.

* 이 아이디어가 어디에서 나왔나? 
  * 가장 나이브한 방법은 모든 값들을 다 살펴보는 것이다. 문제는..
* e.g.
  * rgb 채널은 각 256개. 경우의 수 256 * 256 * 256.
  * 피료한 파라미터 수: 256 * 256 * 256 - 1
  * 즉 파라미터 수가 진짜 많다... 1개의 픽셀에 대해서만...

* e.g.
  * 바이너리 이미지. n개의 픽셀. 2^n개의 경우의 수.
  * 파라미터 수 2^n-1 

* 그래서 현재 값을 예측하기 위해 가까운/주변의 특정 값만을 살펴보자. conditonal independence
* 과거의 모든 값을 살펴본다면...

$$
p\left(x_{1}, \ldots, x_{n}\right)=p\left(x_{1}\right) p\left(x_{2} \mid x_{1}\right) p\left(x_{3} \mid x_{1}, x_{2}\right) \cdots p\left(x_{n} \mid x_{1}, \cdots, x_{n-1}\right)
$$


* t 시점은 t-1시점에만 종속이라면...(markov assumption)  
  * chain rule이 단순. 

$$
p\left(x_{1}, \ldots, x_{n}\right)=p\left(x_{1}\right) p\left(x_{2} \mid x_{1}\right) p\left(x_{3} \mid x_{2}\right) \cdots p\left(x_{n} \mid x_{n-1}\right)
$$

* t-1이 아니라 t-n시점이라고 가정에 따라 모델이 달라짐. auto regressive model이라고 부른다.

* e.g. NADE(Neural Autoregressive Density Estimator)
  * 현재 t번째 노드의 확률을 예측할 때 1번 노드부터 t-1번 까지의 노드들을 고려한다.
  * 그런데 각 노드들은 서로 독립적이다. 
  * 단점: 밑 노드로 갈수록 weight가 커짐.
  * 그래서 신경망에서 그래프들이 서로 엮이지 않음.
  * NADE는 explicit 모델이라서 확률 분포 값을 알아낼 수 있다. 
  * continuous 데이터라면 가우시안을 분포로 사용.

* pixel RNN
  * 바닐라 픽셀 RNN: RNN으로 참조할 픽셀들의 궤적을 결정
  * 주로 LSTM 계열을 사용


# Variational auto encoder VAE.

* 일반적인 인코더 디코더 모델에 확률을 개입시킨 것.
* 인코더는 잠재 변수의 분포를 학습한다. 그래서 평균과 분산을 구한다.
* 디코더는 잠재변수에서부터 생성 분포의 평균과 분산을 학습한다.

https://arxiv.org/pdf/1906.02691.pdf

https://www.cs.cmu.edu/~bhiksha/courses/deeplearning/Spring.2017/slides/lec12.vae.pdf

https://www.youtube.com/watch?v=5WoItGTWV54

http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture13.pdf

https://www.youtube.com/watch?v=odpjk7_tGY0


# GAN

https://arxiv.org/pdf/1406.2661.pdf

* discriminator을 따라 generator도 성능이 향상.
* implicit model

* z라는 latent에서 시작해서 fake가 나온다.
* discriminator가 분류. 차이를 학습.

* gan objective: minmax 게임. 한쪽은 높이고 한쪽은 낮추는 싸움.

* objective
* 최적화 discriminator

* 수식에서 왜 expectation을 쓰는지? 데이터의 분포를 알아내는 것이기 때문이다. 
https://datascience.stackexchange.com/questions/49232/understanding-notation-of-goodfellows-gan-objective-function

* DCGAN
* image 도메인.
* 바닐라 겐은 MLP을 사용했음. 이 논문은 MLP대신에 conv net 사용.

* leaky relu을 썼음. 이미지 만들때는 mlp보다는 deconv 쓰는게 성능이 더 좋더라.

* info gan
  * 잠재 변수 z을 통해 generate을 할 때 class 정보 c을 같이 넣음. 그러면 discriminator가 c 정보를 받아서 c에 특화되어서 분류. multimodel generator가 가능해짐. 

* text2image
  * 문장이 주어자면 이미지 만든다. DallE.

* Puzzle GAN
  * 이미지 안에 sub patch가 있음. sub patch가 있으면 원래 이미지를 복원 함

* Cycle GAN. 이미지 상의 도메인을 바꿈. 굉장히 중요. 
  * cycle consistency loss: 말 사진을 얼룩말 사진으로 바꾸기. 그냥 던져만 줘도 알아서 바꾼다. 같은 위치 필요 없음. 

* star gan
  * 사람의 머리 색, 나이, 성별 바꾸기

* progressive gan
  * 1024 high quality 사진 만들디
  * 4x4에서 쌓아올려서 1024*1024으로 올린다.



