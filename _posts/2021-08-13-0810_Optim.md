---
title: "0810_Optim"
last_modified_at: 2021-08-06T16:20:02-05:00
categories:
  - Blog
  - Camp
tags:
  - camp
---
# week 2 Tue 0810

## 일반화 성능
* traing과 test 성능 차이가 적다
* 물론 학습ㅇ 안좋으면 일반화 성능이좋아도 무의미
* 일반화 성능이 안좋다 : ㅇ버피팅

## k fold
* k개로 나워서 k-1개로 학습하고 1개로 validation으로 하이퍼 파라미터를 탐색.
* 다른 k-1개
* 반복

## trade off
* variance와 bias는 trade off 관계에 있다

## 부트스트래핑
* 섭 샘플링 + 개당 모델링 + 이 값들의 컨센서스로 전체를 예측


## bagging
* 섭 샘플링 + 모델링 + 평균 -> 앙상블
* 부분을 잘 예측하는 weak learner들을 합쳐서 stomg learmer가 되어 작동
 

## mini batch
* sharp minimum가 아니라 flat minimum일 때 어느 정도 차이가 나도 최저값을 만들 수 있다. 
* flat min이면 general 성능이 좋은 것. train에서 극소점이면 test에서도 극소이다. sharp이면 조금만 멀어져도 벌어짐. batch size가 작으면 flat min에 도달 가능을 실험으로 보인 mini batch gd

## 모멘텀
* 관성
* 직전 방향을 유지
* ociliation 적음

## nesterov accel grad
* 관성 방햐응로 한번 가보고 계산하고 accumulate
* 봉우리에 더 빨리 들어간다
* 모멘텀의 문제점: local min을 지나쳤다. 그 자리에서 그래드 계산하면 반대 방향으로 가야 함. 그런데 관성은 벗어나는 방향. 그렇게 왔다 갔다 하면 계속 발산 한다. * nesterov는 간 곳에서 그래드 계산해서 더 빨리 도달. 그러면 그냥 grad랑 다른건 뭐지?

## ada 
* 지금까지 많이 변한 파라미터는 적게 변화시킨다. 적게  변한 파라미터는 적게 변화시킨다. 
* 문제: 갈수록 학습이 더뎌 짐. G가 무한이면 학습은 0이다. G가 monotonically increasing. 
* 해결이 adam delta, adam. 

## RMSprop
  * time step t에서의 slide 구간의 모멘텀을 반영. 문제: 파라미터 1개 당 1개 정보를 가져야. GPT는 파라미터 1000억 개. 이거 다 못가짐. exp avarage in t으로 1개만. adadelta는 러닝 레이트가 없다

## Adam: 가장 무난하다
* 학습이 안된 것을 많이 하는 adaptive learning momentum 사용


## Regularization

* 학습 방해: 테스트 데이터에도 잘 동작하도록
* Early Stopiing
* Parameter Norm Penalty
* 함수 공간에서 함수를 더 부드럽게 하자. 더 일반적이 될 수 있도록.
* Data agumentation
  * 지지고 볶아서 데이터를 더 만들어내는 것

* Noise Robustness
  * 데이터와 weight에 노이즈를 준다. 그럼 실험적으로 일반적 성능이 더 좋더라. 왜 그런지는 아직 논란 중

* Label Smothing
  * 트레인 데이터를 섞음. 고양이와 강아지. 0.5 0.5 cutMix. mix up. 성능이 엄청 커진다. 
* dropout

* batch normliazation
  * 여러 종류의 배치놈. 레이어 놈. 인스턴스 놈. 그룹 놈.

## 과제 인사이트
* 왜 가운데를 잘 맞추나? loss가 큰 부분을 많이 학습해서. 
* SGD는 많이 iter을 돌려도 완전히 맞추지 못함. 
* adamdl daptive와 mementum을 모두 사용. 효교가 좋다. 1/3 iter of sgd 만에 더 완벽히 수렴. 
* adam과 rmsprop가 daptive인 이유: dw의 exponential average을 고려한다. 평균적으로 dW가 큰 W는 적게 학습. 반비례


# viz line
* 연속적 변화하는 값
* 시계열
* 점을 선으로 연결
* .plot
* 5개 이하 사용 추천. 가독성.
* 색상
* 구분
* marker, marker size
* linestyle, linewidth
* 시간으로 변호ㅏ 데이터
* 초 단위 노이즈 > 분 단위 노이즈
* smoothing: 평균만 구해서 깔끔하게 보여준다. 
* 추세가 중요. 0에 축 둘 필요 없음
* 자잘한 것 생략. grid, 숫자 등.
* 실제 숫자가 중요하다? 숫자가 있는 것이 더 좋다 . 
* 데이터 자체가 규칙적이지 않으면 오해가 생김. 기울기가 더 커 보인다
* 그 상태에서 일정하게 하면 없는 데이터도 있어 보인다.
* 그래서 마커를 두면 명확해보인다.(보간)
* 데이터를 선으로 잇는 것. 스무딩
* 이중축
* 두 데이터의 스케일이 다를 때.
* 단위가 다를 때
* 주의: 상관관계가 있어 보임. 
* 두개의 그래프를 따로 사용하는 것이 더 좋을 때가 만다. 
* 팁
* 범례를 라인 끝에 두면 더 깔-끔
* min max을 두면 조음.
* uncertainty를 연한 색으로 두면 좋다.
