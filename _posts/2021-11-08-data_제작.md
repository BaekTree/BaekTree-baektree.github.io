---
title: "1108_data_제작"
last_modified_at: 2021-11-08T16:20:02-05:00
categories:
  - boostcamp
tags:
  - camp
  - data
---


brief
OT
데이터 제작의 중요성
데이터 구축 과정과 설계 기초
자연어처리 데이터

실제 세계의 언어를 어떻게 전산화 데이터로 만들까?

task 별 데이터 특성을 탐구

* 인공지능 서비스 개발 과정과 데이터
  * 서비스 기획 = 문제 정의
  * 데이터 준비 수집 정제 -> 학습 데이터
  * 모델 학습, 검증, 분석, 평가 -> 검증 데이터, 테스트 데이터
  * 배포

전체 개발 과정에서 80이 데이터 수지, 정제에 시간이 든다. 데이터 관련 업무에 더 많은 비용. 여기에서 얼마나 효율적으로 하느냐가 프로젝트의 효율성이 달려있다. 

여기에는 시행착오와 경험적으로 깨달아갈 수 밖에 없다. 

* 데이터 구축과정

1. 원시 데이터 선정 및 확보
저작권과 task 적합성을 고려해야 한다.
기존 데이터셋을 살펴보면 개략적인 과정을 파악 가능. 벤치마킹 가능

2. 구축 및 가공 프로세스 확립
어떻게 데이터 셋 레이블링을 만들지 정한다. 누구에게 얼마나 맡길지. 감독 과정은 어떻게? 레이블링 지침 만들기 등. 플랫폼에 할지. 에이전시에 줄지. 

3. 구축 및 가공 지침  만들기

4. 데이터 구축 및 가공 수행
근데 한번에 안되고, 피드백 하고 이전으로 돌아가서 반복한다. 

5. 데이터 검수
잘 되었는지 검사! 

* 데이터 설계의 구성 요소

데이터 설계
데이터의 형식과 feature을 뭘로 할지

수집-가공설계
어떤 데이터? 어떻게 데이터 수집할지? 



## 데이터 설계
* 유형
  * 소리, 텍스트, 이미지, 영상
  * 캡션 task는 여러개가 같이 나오기도 한다 -> 멀티 모달 데이터
* input output 형식
  * html, xlm, csv, json, ..., jpg, ..., mp3, ...
  * 어떤 형식이 가장 효율적인지 고민해봐야 한다. 중간 중간에 feature을 다루면서 형식이 바뀌기도 하고, 여기서 효율병목이 발생할 수 있음...
* split 규모도 정해야 한다
  * train/validation/test 비율
  * 8,1,1 혹은 3,3,3으로 나눌지 등은 데이터와 task에 따라서 다르다. 
  * random일지 혹은 특정 조건일지도 고민. task에 따라 다르고, 레이블의 분포에 따라서도 달라진다. 
* 주석 유형
  * 클래스 라벨이 단일인지 다중인지
  * 단어 별 레이블(entity type 등)

## 데이터 수집-가공 설계
* 전산화 : 하나 하나 타자로 친다...
* 스크래핑: 가져오기
* 작업자 선정이 전문가를 데려올지 크라우드 소싱으로 대량의 데이터를 빠르게 가지고 올지. 
* 구축 및 검수 설계
  * 파일럿으로 해보고, 본 구축을 ㅗ넘어간다. 
  * 최소수랴은 3만개. 10%정도를 파일럿으로 해본다. 100개~1000개는 직접 해본다. 
* 데이터 구축 및 가공
  * 파일럿: 설계 할때 발견하지 못한 이슈들을 발굴하고 해결 가능!
  * 본구축: 작업자 관리. 일정 관리 등. 결과물 퀄리티 관리 등. 끊임없이 중간 검수하면서 품질 관리 해야 한다. 
  * 평가지표 설정
    * 전문가: 샘플링 검사. 가이드라인을 얼마나 잘 지키고 있는가. 
    * 자동 평가 및 분석: 자동화된 기계에 넣을 때: 데이터 형식이나 레이블별 분포 파악. 
  
## 자연어처리 데이터
자연어 이해와 자연어 생상 task가 있따. 듣고 이해하는 것. 말을 하는 것.
컴퓨터가 사람의 말을 하고 문제를 해결하는 것이 목표. 

# 자연어처리 데이터 기초

## 인공지능을 위한 데이터
* 말뭉치 류
  * 언어 자체
  * 대화문 
  * 기사
  * 댓글
  * ...
* 사전/데이터베이스
  * 참조로 사용되는 자원
  * 워드넷
  * 지식그래프
  * 시소러스
  * ...
* 보통 인공지능 데이터를 만든다고 하면 말뭉치 류이다!
* 모델의 종합적인 자연어 성능을 표현하는 벤치마크 등장
  * GLUE
  * KILT: 지식 기반 자연어 이해
  * GEM: 자연어 생성
* 벤치마크의 구성
  * 각 과제들이 있음
  * 각 과제에 평가/검증/훈련 데이터가 있음
  * 검증/훈련 데이터만 공개
  * 베이스라인 공개
  * 리더보드 서비스 제공

## 데이터 관련 용어 정리
* 텍스트text
  * 본문, 원문
* 말뭉치corpus, plural corpora
  * 기준에 따라 분류해서 저장해둔 것!
  * 근데 그냥 막 써요...
* 데이터
  * 콤퓨타가 접근할 수 있는 정보
* 주석
  * annotation, label, tag, ...
  * 원래 텍스트에 대해서 표현해야 놓아야 할 것에 대해서 태그를 붙이는 것... 형태소에 기호를 붙이는 것... 감성 분석에서 positive, negative을 붙이는 것. 중립/모순/infer인지 붙이는 것. 
  * 이 주석을 붙이는 행위를 주석하다, tagging, labeling
  * 영어는 그래서 POS(part of speech) tagger라고 부름. 한국어는 열망을 담아... 형태소 '분석기'라고 부름...
* 언어학의 연구 분야
  * 어질어질...

* **동사와 형용사는 어미가 바뀐다.**
  * 알면 전처리하는데 아주 아주 좋다.
* 나머지는 그대로~ 으헿

* N-gram
  * 글자수 bigram
    * 글자 수 앞뒤 2자
  * 형태소 bi-gram
    * 형태소 단위 앞뒤 2자
  * 어절 bi-gram
    * 띄어쓰기 기준 2어절 앞뒤 2자

# 자연어처리 데이터 소개1
모두의 말뭉치 - 국립국어원
KLUE, KorQuad, KorNLU

# 데이터 수집과 정제
외주 줄지 크라우드 소싱할지
개인 정보 가리기 등
띄어쓰기 포함?
외국어는?
등등 결정과 실행

# 데이터 구축 작업 설계
MATTER cycle
model:어떤 과정으로 데이터 구축?
annotation
train: 모델에 넣어봄
test
evaluate
revise: 다시 돌아가서 데이터 구축

MAMA cycle
Model -> anotate -> evaluate -> revise

예시
파일럿 구축 -> 파일럿 검수 -> 반영 -> 1차 구축 -> 1차 검수 -> 반영 -> 2차 구축 -> 최종검수 -> 반영



# 데이터 구축 작업 설계
task에 따라 annotation 작업을 다르게 설계한다.
단순한 순서대로
classification
span
Relation
생성
종합

## 데이터 검수
가이드라인은 잘 지켰느지
형식은 잘 맞는지 id, feature에 따라 잘 들어갓는지
통계 정보: 문장 길이, 성별, ..., 레이블의 분포가 잘 맞는지
모델 성능: 모델에 넣어봐서 학습이 잘되는지 확인. 근데 사실 모델에 큰 결함이 없는지를 확인하는 것. 성능이 잘 나온다고 좋은 데이터는 아니다. 

## 발생할 수 있는 오류

구축 방법이 잘못된 경우
가이드라인이 잘못된 경우
데이터셋 자체가 잘못된 경우
잘못된 학습 모델을 선정했을 경우

## 검수 유형
표본 추출과 전수검사

## 데이터 평가
1. 작업자 간 일치도: 작업자들이 동일하게 레이브링 했는가? Cohen's k, Fleiss's k. 
2. 모델 평가: f1, Acc, ROC, ...

# 가이드라인
수집을 위한 가이드라인
주석을 위한 가이드라인
검수를 위한 가이드라인

보통 이렇게 3가지로 나눈다. 문서로 만들지, 튜토리엘로 만들지도 결정.



# 관계 추출 과제 이해

과제에 대한 데이터를 만드려면 과제가 뭔지 이해 해야 한다! 

개체명 인식: 사람, 지역, 기관, 날짜, 시간, 수량

기존의 태그가 없다면 새로운 태크 추가 해야
태그 통폐합


